{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Construindo um LLM do Zero: Tokenização, um mal necessário\n",
    "\n",
    "Este é o **segundo** de uma série de oito artigos que podem ser encontrados no meu medium. Acesse o primeiro artigo da série aqui: [Construindo um LLM: entendendo os Grandes Modelos de Linguagem](https://blog.zfab.me/construindo-um-llm-entendendo-os-grandes-modelos-de-linguagem-b37884219eaa)\n",
    "\n",
    "--\n",
    "\n",
    "Redes neurais profundas, e LLMs são redes neurais profundas, não podem processar texto diretamente e por isso precisamos transforma-lo em algo que o modelo possa consumir e aprender É nesse momento que entra uma etapa crucial na criação de um modelo de linguagem: a tokenização.\n",
    "\n",
    "Imagine que você está tentando montar um quebra-cabeça sem saber como a imagem final deveria ser. As peças estão lá, mas sem entender o contexto ou a forma como se encaixam, é difícil formar uma imagem coerente. Da mesma forma, um modelo de linguagem precisa que o texto seja dividido em \"peças\" menores, ou seja, tokens, para que ele possa começar a construir uma representação significativa do conteúdo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o texto para o modelo\n",
    "\n",
    "A criação de um LLM (Large Language Model ou Modelo de Linguagem de Grande Escala) começa pela preparação cuidadosa do texto que será utilizado no treinamento. Esse passo é fundamental para garantir que o modelo seja capaz de compreender o conteúdo, capturar o significado das palavras e reconhecer suas relações semânticas e sintáticas. Para alcançar esse objetivo, todo o conteúdo de treinamento precisa ser convertido em números - um formato que o modelo pode processar e, a partir disso, aprender de forma eficiente.\n",
    "\n",
    "A abordagem mais simples e intuitiva para processar texto é atribuir um número único a cada palavra e substituir as palavras por esses identificadores sempre que aparecerem. Por exemplo, uma frase como \"Eu adoro ciência de Dados!\" poderia ser convertida em \"1, 4, 10, 2, 13, 25\", onde o número 1 representa a palavra \"eu\", o 13 corresponde a \"dados\" e o 25 indica o ponto de exclamação.\n",
    "Porém para chegarmos nessa lista de palavras e identificadores (o chamado vocabulário) precisamos decidir como dividir nosso texto para identificação das palavras: é nisso que consiste a Tokenização\n",
    "\n",
    "### Tokenização\n",
    "\n",
    "A tokenização pode ser comparada a cortar um grande quebra-cabeça em peças menores. Na prática, trata-se de dividir o texto em unidades chamadas tokens, que podem ser palavras, subpalavras ou até mesmo caracteres individuais. Apesar de a ideia parecer simples, sua implementação pode ser bastante complexa.\n",
    "Um dos primeiros pontos que precisamos ponderar é a forma como vamos dividir nosso texto já que isso influenciará diretamente o tamanho do nosso vocabulário e por consequência a eficiência do nosso modelo. Vamos usar um conjunto de textos em português como exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de Caracteres: 79444559\n",
      "Número de Palavras: 25644299\n",
      "Número de Caracteres únicos: 1265\n",
      "Número de Palavras únicas: 748520\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/gigaverbo.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_raw = f.read()\n",
    "    \n",
    "print(\"Número de Caracteres:\", len(text_raw))\n",
    "print(\"Número de Palavras:\", len(re.split(r\"(\\s)\", text_raw)))\n",
    "print(\"Número de Caracteres únicos:\", len(set(text_raw)))\n",
    "print(\"Número de Palavras únicas:\", len(set(re.split(r\"(\\s)\", text_raw))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliando dois cenários, onde em um quebramos o nosso texto por caractere (cada caractere é um id) e outro separando por palavra (cada palavra única é um id) vemos o impacto no tamanho do vocabulário: no primeiro cenário (separação por caractere) temos um vocabulário com 1265 ids e no segundo cenário (separação por palavras) temos um vocabulário com 748520 ids.\n",
    "\n",
    "![](../assets/2-TOKENIZAÇÃO.png)\n",
    "\n",
    "À primeira vista, a separação por caracteres pode parecer uma abordagem mais vantajosa, já que resulta em um vocabulário significativamente menor - mais de 500 vezes menor em comparação à divisão por palavras - , o que exige menos memória. No entanto, essa escolha traz consigo um impacto negativo, como podemos observar no exemplo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: Hoje é um belo dia\n",
      "Frase em caracteres: [43, 82, 77, 72, 3, 155, 3, 88, 80, 3, 69, 72, 79, 82, 3, 71, 76, 68]\n",
      "Frase em palavras: [179435, 3, 746180, 3, 724737, 3, 355836, 3, 432683]\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Hoje é um belo dia\"\n",
    "\n",
    "# Criando vocabulario de caracteres\n",
    "vocab_char = sorted(set(text_raw))\n",
    "\n",
    "# Criando vocabulario de palavras\n",
    "vocab_word = sorted(set(re.split(r\"(\\s)\", text_raw)))\n",
    "\n",
    "print(\"Frase:\", phrase)\n",
    "print(\"Frase em caracteres:\", [vocab_char.index(c) for c in phrase])\n",
    "print(\"Frase em palavras:\", [vocab_word.index(w) for w in re.split(r\"(\\s)\", phrase)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reparar que apesar do vocabulário por caracteres ser menor a conversão do conteúdo se torna muito mais extensa em comparação com o vocabulário por palavras. Isso quer dizer que a mesma frase necessitará de muito mais processamento para interpretação e relações entre esses caracteres pelo modelo, o que também não é desejado.\n",
    "\n",
    "Um outro problema é o que fazer com palavras desconhecidas. Se tentarmos fazer o encode (converter texto para IDs) de uma frase como \"Fui assistir o lançamento de um foguete\" com nosso vocabulário, criado com texto de Machado de Assis, não teremos algumas palavras como \"lançamento\" e \"foguete\", ou então nomes próprios.\n",
    "\n",
    "![](../assets/2-VOCABULARIO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionarmos esses e outros problemas algumas soluções foram e são propostas rotineiramente. Recentemente, a Meta introduziu o Byte Latent Transformer (BLT), uma arquitetura que elimina a necessidade da tokenização. O BLT processa diretamente sequências de bytes brutos, agrupando-os dinamicamente em \"patches\" de tamanhos variados com base na complexidade dos dados.\n",
    "\n",
    "Atualmente, a solução padrão ouro na industria, usada na maioria dos modelos comerciais, e que usaremos no nosso modelo, é a técnica de Byte Pair Encoding (BPE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Byte Pair Encoding (BPE)\n",
    "\n",
    "\n",
    "O **BPE** (e suas variações) é uma das técnicas mais usadas para lidar com a tokenização atualmente. Originalmente criado como um algoritmo de compressão em 1994, foi adaptado em 2015 por Sennrich et al. ([https://arxiv.org/abs/1508.07909](https://arxiv.org/abs/1508.07909)) para o processamento de linguagem natural para resolver, principalmente, o problema das palavras raras ou completamente desconhecidas.\n",
    "\n",
    "Sua solução é relativamente simples mas eficás: encontrar um equilíbrio entre caracteres individuais e palavras completas, criando subpalavras que maximizam a eficiência.\n",
    "\n",
    "Imagine que você está tokenizando a palavra “araraquara” usando BPE. No início, o algoritmo simplesmente divide a palavra em seus caracteres individuais:\n",
    "\n",
    "`['a', 'r', 'a', 'r', 'a', 'q', 'u', 'a', 'r', 'a']`\n",
    "\n",
    "A partir daí, começa a analisar o texto como um todo e identificamos os **pares de caracteres mais frequentes**. Nesse caso, o par “ar” é o mais comum. Então, ele o combina em um único token:\n",
    "\n",
    "`['ar', 'ar', 'a', 'q', 'u', 'ar', 'a']`\n",
    "\n",
    "O processo continua. O próximo par mais frequente, “ara”, também é combinado:\n",
    "\n",
    "`['ar', 'ara', 'q', 'u', 'ara']`\n",
    "\n",
    "No final, o que começou como 10 tokens foi reduzido para apenas 5. É esse tipo de compactação inteligente que torna o BPE tão eficiente. Ele identifica padrões frequentes e cria novos tokens que representam essas combinações, o que economiza espaço e melhora o desempenho do modelo.\n",
    "\n",
    "A grande sacada do BPE é sua capacidade de representar palavras raras como combinações de subpalavras comuns. Em vez de simplesmente ignorar essas palavras ou tratá-las como completamente desconhecidas, o BPE permite que elas sejam representadas por combinações de tokens que já existem.\n",
    "\n",
    "Por exemplo, uma palavra rara como “descentralização” pode ser dividida em subpalavras como “des”, “central” e “ização”. Mesmo que o modelo nunca tenha visto “descentralização” antes, ele ainda pode entender parte de seu significado por reconhecer essas subpartes.\n",
    "\n",
    "Essa **flexibilidade** permite reduzir significativamente o tamanho do vocabulário, o que economiza recursos computacionais e facilita o treinamento dos modelos.\n",
    "\n",
    "O número de fusões realizadas no Byte Pair Encoding (BPE) é definido por um hiperparâmetro arbitrário, esse número determina o tamanho do vocabulário final e, consequentemente, a granularidade dos tokens. Um vocabulário muito pequeno pode levar a uma divisão excessiva em tokens menores, enquanto um vocabulário muito grande pode resultar em um modelo menos eficiente em termos computacionais.\n",
    "\n",
    "Além disso, a capacidade do tokenizador de representar palavras de forma eficiente depende fortemente do conjunto de textos utilizado. Um conjunto diversificado e representativo oferece ao BPE dados suficientes para aprender padrões frequentes e linguísticamente significativos. Por outro lado, um corpus limitado ou enviesado pode levar o tokenizador a priorizar combinações que não refletem bem a estrutura linguística do idioma ou do domínio.\n",
    "\n",
    "# Nem tudo são flores...\n",
    "\n",
    "\n",
    "A tokenização, embora essencial para o funcionamento de modelos de linguagem de grande escala (LLMs), carrega consigo uma série de desafios que justificam o título de \"mal necessário\".\n",
    "\n",
    "#### A Fragmentação e o Contexto Perdido\n",
    "\n",
    "\n",
    "Um dos maiores problemas da tokenização é a necessidade de fragmentação do texto em unidades menores, como palavras ou subpalavras. Essa divisão, enquanto necessária para o processamento por redes neurais, pode descontextualizar certos elementos linguísticos. Um exemplo clássico são os número, como por exemplo \"6773\", que, dependendo do tokenizador, pode ser dividido em dois ou mais tokens, dificultando a capacidade do modelo de lidar com cálculos ou de entender o significado numérico como um todo​\n",
    "\n",
    "Esse problema se estende a palavras compostas, gírias e outros elementos linguísticos que, quando quebrados, perdem sua semântica original. A incapacidade de capturar adequadamente esses significados pode levar a previsões imprecisas e dificuldades em tarefas como tradução automática ou compreensão de linguagem natural.\n",
    "\n",
    "#### O Impacto do Vocabulário e da Língua\n",
    "\n",
    "\n",
    "Outro desafio está relacionado ao tamanho do vocabulário e à diversidade linguística. Tokenizadores treinados majoritariamente em textos em inglês, por exemplo, tendem a representar frases nesse idioma com menos tokens em comparação a outras línguas, como o português. Isso ocorre porque o treinamento com dados desbalanceados privilegia a compressão de padrões mais frequentes no idioma dominante​ no texto\n",
    "\n",
    "Além disso, vocabulários maiores permitem representar mais informações com menos tokens, mas isso tem um custo: modelos com grandes vocabulários demandam mais memória e poder computacional, além de enfrentarem problemas de subtreinamento em tokens raros, que aparecem com pouca frequência nos dados​\n",
    "\n",
    "#### A Complexidade Matemática e Computacional\n",
    "\n",
    "\n",
    "A tokenização tem um impacto direto no desempenho computacional. Quando o texto é mais fragmentado, o número de tokens a serem processados aumenta, o que eleva tanto o tempo de treinamento quanto os requisitos de memória. Por outro lado, técnicas como o Byte Pair Encoding (BPE) compactam as informações em menos tokens, criando vocabulários mais densos.\n",
    "\n",
    "Embora esses vocabulários densos sejam eficientes, eles exigem maior capacidade computacional para gerar embeddings mais complexos. Essa complexidade adicional é um aspecto importante a se considerar no desenvolvimento de modelos de linguagem. No próximo artigo, abordaremos mais detalhadamente o tema dos embeddings.\n",
    "\n",
    "# Iniciando nosso LLM\n",
    "\n",
    "\n",
    "Para iniciar o desenvolvimento do nosso LLM, o primeiro passo é construir o Tokenizador. Além de escolhermos a técnica que utilizaremos, que será a BPE (Byte Pair Encoding), é crucial selecionar o corpus adequado.\n",
    "\n",
    "O conjunto de textos escolhido é de extrema importância, pois determinará os tokens que nosso modelo será capaz de reconhecer. Por exemplo, se o corpus não contiver a palavra \"foguete\", essa palavra será representada por vários tokens, dificultando a capacidade do nosso LLM de compreender seu significado de forma eficaz.\n",
    "\n",
    "Nos treinaremos, tanto nosso tokenizador quanto nosso LLM, em uma parte do dataset chamado **GigaVerbo**. Esse dataset está disponível no [HuggingFace](https://huggingface.co/datasets/TucanoBR/GigaVerbo) e contém mais de 200 bilhões de tokens em português e faz parte do trabalho realizado pelo Nicholas Kluge na criação do modelo Tucano (o paper pode ser lido no Arxiv: [https://arxiv.org/abs/2411.07854](https://arxiv.org/abs/2411.07854))\n",
    "\n",
    "Para conseguir acesso aos dados, usaremos o link disponibilizado pelo HuggingFace. Faremos o download do arquivo `train-00000-of-01573.parquet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92372 linhas e 4 colunas (text, label, probs, metadata)\n"
     ]
    }
   ],
   "source": [
    "# Download primeira parte do dataset\n",
    "df = pl.read_parquet('hf://datasets/TucanoBR/GigaVerbo/data/train-00000-of-01573.parquet')\n",
    "\n",
    "print(f\"{df.shape[0]} linhas e {df.shape[1]} colunas ({\", \".join(df.columns)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, o dataset contém mais de 92 mil textos (de diversos tamanhos) e todos recebem uma label, a probabilidade do texto pertencer ao label e a origem do conteúdo (metadata). O label indica se o texto foi considerado de boa qualidade ou não.\n",
    "\n",
    "Para fazer essa classificação de qualidade o time do Tucano treinou um outro modelo para isso e pode ser visto em detalhes no paper. Para nós o importante aqui é entender que label 1 quer dizer que o texto foi considerado de qualidade e serão esses que usaremos no nosso treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas textos com label 1 (texto de qualidade) e concatenar em uma única string\n",
    "text_raw = \"<|eos|>\".join(\n",
    "    df.filter(\n",
    "        pl.col('label') == 1)\n",
    "    .select(\n",
    "        pl.col('text'))\n",
    "    .to_series()\n",
    "    .to_list()\n",
    ")\n",
    "\n",
    "with open('../data/gigaverbo.txt', 'w') as f:\n",
    "    f.write(text_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegamos todos os conteúdos classificados com label 1 (texto de qualidade) e os concatenamos, separando-os por um token especial: <|eos|>.  \n",
    "\n",
    "Os *special tokens* (tokens especiais) desempenham um papel crucial na estruturação e compreensão de dados textuais por modelos de linguagem. Esses tokens são elementos simbólicos adicionados à tokenização com funções específicas. Por exemplo, o token <|eos|> (end of sequence) é utilizado para indicar o fim de um segmento de texto, ajudando o modelo a diferenciar entre contextos ou trechos independentes.\n",
    "\n",
    "## Treinando nosso Tokenizador\n",
    "\n",
    "\n",
    "Para treinar o Tokenizador usaremos a biblioteca `sentencepiece` desenvolvida pelo google e que permite a criação de vocabulários a partir de diversas técnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ../data/gigaverbo.txt\n",
      "  input_format: text\n",
      "  model_prefix: ../models/gigaverbo_tk\n",
      "  model_type: BPE\n",
      "  vocab_size: 4096\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 8\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 1\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 1\n",
      "  user_defined_symbols: <|eos|>\n",
      "  required_chars: \n",
      "  byte_fallback: 1\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface: <|unk|>\n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: identity\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: ../data/gigaverbo.txt\n",
      "trainer_interface.cc(380) LOG(WARNING) Found too long line (32879244 > 4192).\n",
      "trainer_interface.cc(382) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(383) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 282642 sentences\n",
      "trainer_interface.cc(416) LOG(INFO) Skipped 1 too long sentences.\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <|eos|>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x00>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x01>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x02>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x03>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x04>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x05>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x06>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x07>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x08>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x09>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x10>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x11>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x12>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x13>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x14>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x15>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x16>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x17>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x18>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x19>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x20>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x21>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x22>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x23>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x24>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x25>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x26>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x27>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x28>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x29>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x30>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x31>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x32>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x33>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x34>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x35>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x36>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x37>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x38>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x39>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x40>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x41>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x42>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x43>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x44>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x45>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x46>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x47>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x48>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x49>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x50>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x51>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x52>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x53>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x54>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x55>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x56>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x57>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x58>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x59>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x60>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x61>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x62>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x63>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x64>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x65>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x66>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x67>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x68>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x69>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x70>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x71>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x72>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x73>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x74>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x75>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x76>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x77>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x78>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x79>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7E>\n",
      "train"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "er_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x80>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x81>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x82>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x83>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x84>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x85>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x86>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x87>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x88>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x89>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x90>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x91>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x92>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x93>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x94>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x95>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x96>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x97>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x98>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x99>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xED>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFF>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=46032074\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.5011% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=75\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.995011\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 282283 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 282283\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 322338\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=834751 min_freq=217\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=267598 size=20 all=3639 active=2262 piece=▁o\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=151084 size=40 all=5101 active=3724 piece=ara\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=99642 size=60 all=6399 active=5022 piece=▁re\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69568 size=80 all=7892 active=6515 piece=▁g\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51852 size=100 all=9250 active=7873 piece=us\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51692 min_freq=4966\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45281 size=120 all=11061 active=2648 piece=ho\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38712 size=140 all=12636 active=4223 piece=▁en\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32130 size=160 all=14147 active=5734 piece=ça\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27911 size=180 all=15651 active=7238 piece=ém\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23849 size=200 all=17074 active=8661 piece=ido\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=23810 min_freq=4381\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21813 size=220 all=18656 active=2514 piece=ens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20004 size=240 all=19783 active=3641 piece=ntes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18184 size=260 all=21396 active=5254 piece=▁inc\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16102 size=280 all=22832 active=6690 piece=orn\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14743 size=300 all=23731 active=7589 piece=▁dif\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14685 min_freq=3156\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13793 size=320 all=24951 active=2397 piece=▁ele\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12734 size=340 all=26161 active=3607 piece=ade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11679 size=360 all=27420 active=4866 piece=▁algu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11030 size=380 all=28426 active=5872 piece=cont\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10517 size=400 all=29343 active=6789 piece=▁As\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10457 min_freq=2303\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9930 size=420 all=30316 active=2405 piece=▁fin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9515 size=440 all=31343 active=3432 piece=▁rela\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8905 size=460 all=32181 active=4270 piece=.[\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8489 size=480 all=32914 active=5003 piece=▁informações\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8098 size=500 all=33600 active=5689 piece=iss\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8083 min_freq=1858\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7693 size=520 all=34277 active=2239 piece=por\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7424 size=540 all=34719 active=2681 piece=icion\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7129 size=560 all=35577 active=3539 piece=▁usu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6928 size=580 all=36345 active=4307 piece=ientes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6657 size=600 all=36858 active=4820 piece=tes\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6653 min_freq=1584\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6362 size=620 all=37467 active=2357 piece=urante\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6203 size=640 all=38041 active=2931 piece=rut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5967 size=660 all=38776 active=3666 piece=▁me\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5749 size=680 all=39692 active=4582 piece=car\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5610 size=700 all=40533 active=5423 piece=anc\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5604 min_freq=1344\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5485 size=720 all=41096 active=2496 piece=gor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5339 size=740 all=41616 active=3016 piece=ient\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5212 size=760 all=42086 active=3486 piece=▁cul\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5030 size=780 all=42336 active=3736 piece=íst\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4881 size=800 all=42756 active=4156 piece=▁vari\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4877 min_freq=1198\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4757 size=820 all=43668 active=3035 piece=tal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4590 size=840 all=44384 active=3751 piece=▁casa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4438 size=860 all=45124 active=4491 piece=▁sé\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4321 size=880 all=45665 active=5032 piece=▁prote\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4170 size=900 all=46037 active=5404 piece=▁envol\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4156 min_freq=1061\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4067 size=920 all=46419 active=2673 piece=▁result\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3992 size=940 all=47350 active=3604 piece=af\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3867 size=960 all=47866 active=4120 piece=mes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3783 size=980 all=48397 active=4651 piece=inho\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3703 size=1000 all=48921 active=5175 piece=inda\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3694 min_freq=942\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3638 size=1020 all=49476 active=2984 piece=par\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3570 size=1040 all=50293 active=3801 piece=áticas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3515 size=1060 all=50914 active=4422 piece=▁Eles\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3442 size=1080 all=51430 active=4938 piece=▁ainda\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3388 size=1100 all=51964 active=5472 piece=one\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3371 min_freq=848\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3283 size=1120 all=52553 active=3093 piece=gue\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3218 size=1140 all=53298 active=3838 piece=Gere\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3153 size=1160 all=53481 active=4021 piece=▁conse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3089 size=1180 all=54176 active=4716 piece=bora\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3021 size=1200 all=54571 active=5111 piece=ger\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3018 min_freq=780\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2972 size=1220 all=54932 active=3003 piece=▁relação\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2902 size=1240 all=55245 active=3316 piece=rutura\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2840 size=1260 all=55645 active=3716 piece=▁precisa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2803 size=1280 all=56206 active=4277 piece=tro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2745 size=1300 all=56498 active=4569 piece=▁seguir\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2743 min_freq=726\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2694 size=1320 all=56989 active=3311 piece=▁comunicação\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2660 size=1340 all=57278 active=3600 piece=▁armazen\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2596 size=1360 all=57882 active=4204 piece=▁elétr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2547 size=1380 all=58336 active=4658 piece=▁passa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2502 size=1400 all=58885 active=5207 piece=ton\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2499 min_freq=667\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2448 size=1420 all=59492 active=3445 piece=▁estar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2398 size=1440 all=59904 active=3857 piece=▁expres\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2356 size=1460 all=60362 active=4315 piece=▁virtu\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2308 size=1480 all=60846 active=4799 piece=xima\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2261 size=1500 all=61171 active=5124 piece=pend\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2258 min_freq=622\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2207 size=1520 all=61669 active=3513 piece=ndem\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2181 size=1540 all=61975 active=3819 piece=▁amigos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2144 size=1560 all=62401 active=4245 piece=▁sens\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2102 size=1580 all=62678 active=4522 piece=▁ir\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2069 size=1600 all=63058 active=4902 piece=ance\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2068 min_freq=584\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2046 size=1620 all=63492 active=3536 piece=▁refer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2026 size=1640 all=63959 active=4003 piece=▁saudável\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1986 size=1660 all=64453 active=4497 piece=inheiro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1961 size=1680 all=64774 active=4818 piece=ída\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1919 size=1700 all=65252 active=5296 piece=bra\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1917 min_freq=544\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1899 size=1720 all=65824 active=3744 piece=▁sin\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1865 size=1740 all=66259 active=4179 piece=fici\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1845 size=1760 all=66595 active=4515 piece=▁confor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1816 size=1780 all=67016 active=4936 piece=▁pelas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1794 size=1800 all=67387 active=5307 piece=▁decid\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1792 min_freq=511\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1773 size=1820 all=67980 active=3951 piece=▁escolha\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1756 size=1840 all=68362 active=4333 piece=▁começou\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1737 size=1860 all=68624 active=4595 piece=▁inde\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1709 size=1880 all=68945 active=4916 piece=▁caso\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1688 size=1900 all=69114 active=5085 piece=▁test\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1687 min_freq=480\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1675 size=1920 all=69488 active=3813 piece=▁crí\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1652 size=1940 all=69809 active=4134 piece=▁desenvolver\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1634 size=1960 all=70252 active=4577 piece=▁expl\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1620 size=1980 all=70545 active=4870 piece=▁integra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1605 size=2000 all=70970 active=5295 piece=ulas\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1605 min_freq=454\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1579 size=2020 all=71260 active=3814 piece=▁política\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1558 size=2040 all=71468 active=4022 piece=iro\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1540 size=2060 all=71734 active=4288 piece=íder\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1518 size=2080 all=71916 active=4470 piece=▁ga\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1498 size=2100 all=72161 active=4715 piece=ificado\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1497 min_freq=435\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1480 size=2120 all=72588 active=4010 piece=orre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1464 size=2140 all=72842 active=4264 piece=▁humana\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1446 size=2160 all=73375 active=4797 piece=▁possíveis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1423 size=2180 all=73702 active=5124 piece=▁bran\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1409 size=2200 all=73954 active=5376 piece=▁decisão\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1409 min_freq=414\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1388 size=2220 all=74035 active=3779 piece=▁maiores\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1369 size=2240 all=74389 active=4133 piece=▁individ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1358 size=2260 all=74526 active=4270 piece=▁Essas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1341 size=2280 all=74743 active=4487 piece=▁necessidade\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1324 size=2300 all=74951 active=4695 piece=ocar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1324 min_freq=397\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1309 size=2320 all=75106 active=3868 piece=▁consci\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1294 size=2340 all=75331 active=4093 piece=▁início\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1279 size=2360 all=75640 active=4402 piece=ênio\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1269 size=2380 all=76002 active=4764 piece=grafo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1254 size=2400 all=76086 active=4848 piece=ical\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1254 min_freq=381\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1236 size=2420 all=76603 active=4274 piece=ório\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1223 size=2440 all=76989 active=4660 piece=▁superf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1209 size=2460 all=77374 active=5045 piece=▁amea\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1192 size=2480 all=77554 active=5225 piece=▁computação\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1178 size=2500 all=77789 active=5460 piece=▁string\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1178 min_freq=361\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1165 size=2520 all=78196 active=4293 piece=▁preciso\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1148 size=2540 all=78411 active=4508 piece=▁plataforma\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1141 size=2560 all=78819 active=4916 piece=▁promover\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1125 size=2580 all=79011 active=5108 piece=▁Ra\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1112 size=2600 all=79341 active=5438 piece=ún\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1112 min_freq=345\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1104 size=2620 all=79658 active=4242 piece=▁tema\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1095 size=2640 all=79900 active=4484 piece=▁volta\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1085 size=2660 all=80284 active=4868 piece=▁feliz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1072 size=2680 all=80636 active=5220 piece=▁Era\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1063 size=2700 all=80911 active=5495 piece=▁aquecimento\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1062 min_freq=329\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1053 size=2720 all=81138 active=4273 piece=mentação\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1045 size=2740 all=81404 active=4539 piece=▁peso\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1034 size=2760 all=81759 active=4894 piece=▁específico\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1025 size=2780 all=82014 active=5149 piece=▁Sal\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1010 size=2800 all=82174 active=5309 piece=▁explorar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1008 min_freq=316\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1000 size=2820 all=82605 active=4538 piece=formas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=988 size=2840 all=82705 active=4638 piece=ly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=980 size=2860 all=82983 active=4916 piece=lês\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=972 size=2880 all=83319 active=5252 piece=▁concor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=963 size=2900 all=83504 active=5437 piece=▁lar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=963 min_freq=304\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=950 size=2920 all=83816 active=4475 piece=minist\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=942 size=2940 all=84054 active=4713 piece=▁riscos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=930 size=2960 all=84267 active=4926 piece=▁transmit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=920 size=2980 all=84540 active=5199 piece=▁motor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=915 size=3000 all=84705 active=5364 piece=▁próxim\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=915 min_freq=294\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=911 size=3020 all=84809 active=4338 piece=▁frequência\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=903 size=3040 all=84996 active=4525 piece=Con\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=895 size=3060 all=85197 active=4726 piece=▁amplamente\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=885 size=3080 all=85434 active=4963 piece=▁sor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=880 size=3100 all=85612 active=5141 piece=damente\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=880 min_freq=286\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=871 size=3120 all=85943 active=4603 piece=▁saída\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=860 size=3140 all=86261 active=4921 piece=▁cho\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=853 size=3160 all=86648 active=5308 piece=ferência\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=844 size=3180 all=86795 active=5455 piece=eios\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=839 size=3200 all=87051 active=5711 piece=▁tempos\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=839 min_freq=276\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=832 size=3220 all=87199 active=4501 piece=▁década\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=827 size=3240 all=87450 active=4752 piece=▁excess\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=817 size=3260 all=87672 active=4974 piece=cle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=810 size=3280 all=87969 active=5271 piece=ks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=805 size=3300 all=88320 active=5622 piece=▁equilib\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=804 min_freq=266\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=798 size=3320 all=88547 active=4633 piece=inária\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=793 size=3340 all=88721 active=4807 piece=ismos\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=789 size=3360 all=88852 active=4938 piece=▁orçamento\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=783 size=3380 all=88998 active=5084 piece=▁sustentáveis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=777 size=3400 all=89172 active=5258 piece=▁escal\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=777 min_freq=258\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=772 size=3420 all=89415 active=4674 piece=▁rotina\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=765 size=3440 all=89601 active=4860 piece=▁time\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=760 size=3460 all=89705 active=4964 piece=▁praia\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=752 size=3480 all=89855 active=5114 piece=▁perspec\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=745 size=3500 all=89977 active=5236 piece=gân\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=745 min_freq=250\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=738 size=3520 all=90176 active=4690 piece=▁considerar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=730 size=3540 all=90301 active=4815 piece=▁baixa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=721 size=3560 all=90580 active=5094 piece=▁Pol\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=716 size=3580 all=90826 active=5340 piece=▁Aumento\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=707 size=3600 all=91052 active=5566 piece=órnia\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=707 min_freq=241\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=701 size=3620 all=91226 active=4725 piece=▁Cont\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=697 size=3640 all=91345 active=4844 piece=bate\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=692 size=3660 all=91572 active=5071 piece=▁vento\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=685 size=3680 all=91803 active=5302 piece=▁ensa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=681 size=3700 all=91951 active=5450 piece=▁levando\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=681 min_freq=234\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=677 size=3720 all=92135 active=4782 piece=▁álb\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=674 size=3740 all=92334 active=4981 piece=▁filho\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=669 size=3760 all=92445 active=5092 piece=▁descont\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: ../models/gigaverbo_tk.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: ../models/gigaverbo_tk.vocab\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 4096\n",
    "SPECIAL_TOKENS = [\"<|eos|>\"]\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=\"../data/gigaverbo.txt\",              # Caminho para o arquivo de contendo o conteúdo para treinar o tokenizador\n",
    "    model_prefix=\"../models/gigaverbo_tk\",     # Prefixo do nome do arquivo de saída\n",
    "    vocab_size=VOCAB_SIZE,                          # Tamanho do vocabulário\n",
    "    model_type=\"bpe\",                               # Tipo do tokenizador\n",
    "    self_test_sample_size=0,                        # Tamanho do conjunto de teste (não utilizaremos)\n",
    "    character_coverage=0.995,                       # Fração de caracteres que devem ser cobertos pelo modelo\n",
    "    input_format=\"text\",                            # Formato do arquivo de entrada\n",
    "    num_threads=os.cpu_count(),                     # Número de threads a serem utilizadas\n",
    "    split_digits=True,                              # Separar os dígitos tratando-os como tokens separados\n",
    "    allow_whitespace_only_pieces=True,              # Permitir tokens que representem apenas espaços em branco\n",
    "    byte_fallback=True,                             # Utilizar tokenização de bytes como fallback\n",
    "    unk_surface=\"<|unk|>\",                          # Representação do token desconhecido\n",
    "    normalization_rule_name=\"identity\",             # Regra de normalização (identity = sem normalização)\n",
    "    user_defined_symbols=SPECIAL_TOKENS             # Adiciona tokens especiais definidos pelo usuário\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após o treinamento, dois arquivos serão gerados: o `gigaverbo_tk.model` e o `gigaverbo_tk.vocab` . O arquivo .model contém as informações sobre o modelo, como tipo do tokenizador, forma em que números foram divididos entre outras informações. Já o .vocab é nossa grande lista contendo os tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase Tokenizada: ['▁Ol', 'á', '▁Mu', 'ndo', ',', '▁tudo', '▁bem', '?', '<|eos|>']\n",
      "Frase tokenizada: [3188, 4047, 2362, 341, 4040, 1927, 824, 4091, 3]\n",
      "Frase reconstruída: Olá Mundo, tudo bem?<|eos|>\n"
     ]
    }
   ],
   "source": [
    "phrase = \"Olá Mundo, tudo bem?<|eos|>\"\n",
    "\n",
    "tk = spm.SentencePieceProcessor(model_file=\"../models/gigaverbo_tk.model\") # Instanciando o tokenizador treinado\n",
    "\n",
    "phrase_encode = tk.encode(phrase)\n",
    "phrase_tokens = tk.encode_as_pieces(phrase)\n",
    "phrase_decode = tk.decode(phrase_encode)\n",
    "\n",
    "print(\"Frase Tokenizada:\", phrase_tokens)\n",
    "print(\"Frase tokenizada:\", phrase_encode)\n",
    "print(\"Frase reconstruída:\", phrase_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo acima podemos ver a codificação da frase \"Olá Mundo, tudo bem?\" onde temos a palavra *Olá* sendo separada em dois tokens, `_Ol` (O sinal de _ significa que é um token inicial, ou seja, está no começo de uma palavra) e `á`. Podemos também ver que `_tudo` é um único token de ID **1927** enquanto o ? é representado pelo ID **4091**. Nosso token especial, <|eos|> é de ID **3**.\n",
    "\n",
    "Vamos agora tokenizar nosso corpus (o conjunto de textos que extraímos do GigaVerbo) para que possamos utiliza-lo sem precisar converte-lo em tokens toda vez que formos iniciar o treinamento do LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostra do texto tokenizado: [2762, 1993, 596, 900, 271, 613, 445, 2710, 845, 4002, 372, 3651, 3479, 4091, 14, 14, 2385, 2258, 2188, 269, 1041, 1332, 4040, 2001, 1110, 374, 310, 1456, 739, 3763, 261, 866, 513, 301, 486, 547, 4037, 951, 1556, 296, 1294, 1064, 301, 888, 261, 1045, 1087, 4040, 323, 435, 298, 4036, 614, 302, 607, 1354, 596, 900, 271, 613, 733, 4030, 914, 445, 2710, 845, 4002, 372, 3651, 3479, 4040, 595, 323, 935, 1071, 1146, 2443, 362, 262, 1401, 297, 451, 269, 765, 4037, 14, 14, 4055, 4031, 885, 4040, 367, 2710, 845, 4002, 1339, 453, 1803, 828, 769]\n"
     ]
    }
   ],
   "source": [
    "text_tokenized = tk.encode(text_raw)\n",
    "\n",
    "# Salvando o texto tokenizado\n",
    "with open(\"../data/gigaverbo_tokenized.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\" \".join([str(t) for t in text_tokenized]))\n",
    "\n",
    "print(\"Amostra do texto tokenizado:\", text_tokenized[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto! Nosso corpus está devidamente tokenizado. Agora, o próximo passo é transformar esses identificadores de tokens em algo que vá além de números aleatórios — algo que carregue significado e seja capaz de representar a semântica de cada token. É nesse momento que os ***Embeddings*** entram em cena e brilham!\n",
    "\n",
    "# Conclusão\n",
    "\n",
    "\n",
    "A tokenização é a ponte que conecta texto a números, mas é uma ponte cheia de buracos e obstáculos. Ela define como os modelos “enxergam” o mundo, mas também podem limitar sua capacidade de entender certos contextos. Apesar de seus problemas a tokenização ainda é indispensável.\n",
    "\n",
    "Ao explorarmos as complexidades da tokenização, percebemos uma dança entre precisão semântica e eficiência computacional. A escolha do corpus e técnica de tokenização, assim como o tamanho do vocabulário são passos importantíssimos no caminho para desenvolver um LLM.\n",
    "\n",
    "No próximo artigo, exploraremos outra peça fundamental no funcionamento dos grandes modelos de linguagem: os **embeddings**. Se o mecanismo de atenção é o coração dos LLMs, os embeddings são o sangue que flui, carregando os significados e relações complexas que sustentam toda a compreensão linguística do modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
